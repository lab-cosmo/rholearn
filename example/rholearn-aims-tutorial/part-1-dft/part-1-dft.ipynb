{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Generating data with `FHI-aims` (supporting notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BASE_AIMS': {'xc': 'pbe0',\n",
       "  'spin': 'none',\n",
       "  'charge': 0,\n",
       "  'relativistic': 'atomic_zora scalar'},\n",
       " 'SCF': {'elsi_restart': 'write 1000', 'output': 'cube total_density'},\n",
       " 'RI': {'ri_full_output': True,\n",
       "  'ri_density_restart': 'write',\n",
       "  'default_max_l_prodbas': None,\n",
       "  'default_prodbas_acc': '1e-5',\n",
       "  'elsi_restart': 'read',\n",
       "  'ri_skip_scf': True,\n",
       "  'ri_ovlp_write_triu': True},\n",
       " 'REBUILD': {'ri_density_restart': 'read 0',\n",
       "  'ri_full_output': True,\n",
       "  'default_max_l_prodbas': None,\n",
       "  'default_prodbas_acc': '1e-5',\n",
       "  'output': 'cube total_density'},\n",
       " 'CUBE': {'n_points': [100, 100, 100]},\n",
       " 'RI_FIT_ID': 'edensity',\n",
       " 'FIELD_NAME': 'edensity',\n",
       " 'MASK': None,\n",
       " 'DATA_DIR': '/home/abbott/codes/rholearn/example/rholearn-aims-tutorial/part-1-dft/data',\n",
       " 'XYZ': '/home/abbott/codes/rholearn/example/rholearn-aims-tutorial/part-1-dft/data/qm7_16.xyz',\n",
       " 'AIMS_COMMAND': 'srun /home/abbott/codes/aims_files/binaries/aims.240925.scalapack.mpi.x < control.in > aims.out',\n",
       " 'SPECIES_DEFAULTS': '/home/abbott/codes/rholearn/example/rholearn-aims-tutorial/part-1-dft/species_defaults/light/default'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from os.path import exists, join\n",
    "import chemiscope\n",
    "\n",
    "import numpy as np\n",
    "import metatensor as mts\n",
    " \n",
    "from rholearn.utils import cube, system\n",
    "from rholearn.utils.io import unpickle_dict\n",
    "from rholearn.options import get_options\n",
    "\n",
    "dft_options = get_options(\"dft\")\n",
    "dft_options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e020a13dd1e4bf8a904adaa3349aede",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<StructureWidget(meta={'name': ' '}, structures=[{'size': 21, 'names': ['C', 'C', 'N', 'C', 'N', 'C', 'C', 'H', ...}, properties={'index': {'target': 'structure', 'values': [0.0, 1.0, 2.0, 3.0,...}, )>"
      ],
      "text/plain": [
       "<StructureWidget(meta={'name': ' '}, structures=[{'size': 21, 'names': ['C', 'C', 'N', 'C', 'N', 'C', 'C', 'H'â€¦"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the nuclear geometries with chemiscope\n",
    "frames = system.read_frames_from_xyz(dft_options[\"XYZ\"])\n",
    "frame_idxs = range(len(frames))\n",
    "chemiscope.show(system.chemfiles_frame_to_ase_frame(frames), mode=\"structure\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2: Converge SCF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check all SCF calculations have converged\n",
    "scf_dir = lambda A: f\"data/raw/{A}\"\n",
    "\n",
    "not_conv = []\n",
    "for A in frame_idxs:\n",
    "    path = join(scf_dir(A), \"aims.out\")\n",
    "    if not exists(path):\n",
    "        not_conv.append(A)\n",
    "    else:\n",
    "        with open(path, \"r\") as f:\n",
    "            if \"Have a nice day.\" not in f.read():\n",
    "                not_conv.append(A)\n",
    "\n",
    "assert len(not_conv) == 0, f\"SCF not converged for {not_conv}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm again all SCF calculations have converged via the parsed aims.out files\n",
    "for A in frame_idxs:\n",
    "    calc_info = unpickle_dict(join(scf_dir(A), \"calc_info.pickle\"))\n",
    "    assert calc_info[\"scf\"][\"converged\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WARNING: execute with care! \n",
    "# Display the electron density volumetric data. This relies on py3Dmol, which is often\n",
    "# unreliable in jupyter notebooks. Better to use another external software, such as\n",
    "# VESTA.\n",
    "\n",
    "# Display the electron density of structure 0\n",
    "A = 0\n",
    "rhocube = cube.RhoCube(join(scf_dir(A), \"cube_001_total_density.cube\"))\n",
    "rhocube.show_volumetric()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3: Perform RI decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check all RI calculations have finished\n",
    "ri_dir = lambda A: f\"data/raw/{A}/edensity\"\n",
    "\n",
    "not_finished = []\n",
    "for A in frame_idxs:\n",
    "    path = join(ri_dir(A), \"aims.out\")\n",
    "    if not exists(path):\n",
    "        not_conv.append(A)\n",
    "    else:\n",
    "        with open(path, \"r\") as f:\n",
    "            if \"Have a nice day.\" not in f.read():\n",
    "                not_conv.append(A)\n",
    "\n",
    "assert len(not_finished) == 0, f\"RI not finished for {not_finished}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lmax': {'C': 4, 'N': 4, 'H': 2},\n",
       " 'nmax': {('C', 0): 9,\n",
       "  ('C', 1): 7,\n",
       "  ('C', 2): 7,\n",
       "  ('C', 3): 3,\n",
       "  ('C', 4): 1,\n",
       "  ('N', 0): 9,\n",
       "  ('N', 1): 8,\n",
       "  ('N', 2): 7,\n",
       "  ('N', 3): 3,\n",
       "  ('N', 4): 1,\n",
       "  ('H', 0): 4,\n",
       "  ('H', 1): 3,\n",
       "  ('H', 2): 1}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inpsect the basis set definition for frame 0\n",
    "processed_dir = lambda A: f\"data/processed/{A}/edensity\"  # relative dir\n",
    "\n",
    "A = 0\n",
    "unpickle_dict(join(processed_dir(A), \"basis_set.pickle\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the metadata structure of the coefficient vector and overlap matrix\n",
    "coeffs = mts.load(join(processed_dir(A), \"ri_coeffs.npz\"))\n",
    "ovlp = mts.load(join(processed_dir(A), \"ri_ovlp.npz\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorMap with 13 blocks\n",
       "keys: o3_lambda  o3_sigma  center_type\n",
       "          0         1           6\n",
       "          1         1           6\n",
       "                    ...\n",
       "          3         1           7\n",
       "          4         1           7"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The coefficient (and projection) vector is a 1D array, stored in a block sparse\n",
    "# format. As it represents an equivariant target property (i.e. the density decomposed\n",
    "# onto a spherical basis), knowing the spherical symmetry of each block - in terms of\n",
    "# `o3_lambda` and `o3_sigma` - is crucial for unserstanding the bahviour under rotation\n",
    "# and what equivariance-preserving operations can be applied.\n",
    "coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorBlock\n",
       "    samples (5): ['system', 'atom']\n",
       "    components (3): ['o3_mu']\n",
       "    properties (7): ['radial_n']\n",
       "    gradients: None"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The first axis of each block is the atomic samples. The intermediate axis is the\n",
    "# spherical harmonics components, and the properties (last axis) is the radial basis\n",
    "# function index.\n",
    "coeffs.block(o3_lambda=1, o3_sigma=1, center_type=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorMap with 7 blocks\n",
       "keys: center_1_type  center_2_type\n",
       "            6              6\n",
       "            6              7\n",
       "                  ...\n",
       "            7              1\n",
       "            1              1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The overlap matrix is stored with pairs of center types (i.e. chemical species) as\n",
    "# sparse keys. These have consistent basis set definitions, so overlap matrices between\n",
    "# atoms can be stacked.\n",
    "ovlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorBlock\n",
       "    samples (15): ['system', 'atom_1', 'atom_2']\n",
       "    components (95): ['l1_n1_m1']\n",
       "    properties (95): ['l2_n2_m2']\n",
       "    gradients: None"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For each center type pair, the overlaps between basis functions of pairs of atoms of\n",
    "# types center_1_type and center_2_type are stacked along the samples (first) axis.\n",
    "ovlp.block(center_1_type=6, center_2_type=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NMAE (%)\n",
      "   Min  :  0.2397463093683903\n",
      "   Mean :  0.262958566601245\n",
      "   Max  :  0.2822949031750377\n"
     ]
    }
   ],
   "source": [
    "# Calculate the normalised MAE, averaged over all structures\n",
    "nmaes = []\n",
    "for A in frame_idxs:\n",
    "    df_error = unpickle_dict(\n",
    "        join(processed_dir(A), \"df_error.pickle\")\n",
    "    )\n",
    "    nmae = 100 * df_error['abs_error'] / df_error['norm']\n",
    "    nmaes.append(nmae)\n",
    "\n",
    "print(\"NMAE (%)\")\n",
    "print(\"   Min  : \", np.min(nmaes))\n",
    "print(\"   Mean : \", np.mean(nmaes))\n",
    "print(\"   Max  : \", np.max(nmaes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: check that the RI rebuilt density output in the RI procesure is equivalent\n",
    "# to the density rebuilt from the corresponding coefficients.\n",
    "from rholearn.aims_interface import fields\n",
    "\n",
    "rebuild_dir = lambda A: f\"data/raw/{A}/edensity/rebuild\"  # relative dir\n",
    "\n",
    "# Check for the first structure\n",
    "A = 0\n",
    "abs_error, norm = fields.field_absolute_error(\n",
    "    input=np.loadtxt(join(rebuild_dir(A), \"rho_rebuilt_ri.out\")),\n",
    "    target=np.loadtxt(join(ri_dir(A), \"rho_rebuilt_ri.out\")),\n",
    "    grid=np.loadtxt(join(ri_dir(A), \"partition_tab.out\"))\n",
    ")\n",
    "\n",
    "assert 100 * abs_error / norm < 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rho",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
