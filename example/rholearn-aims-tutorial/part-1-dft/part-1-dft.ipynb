{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Generating data with `FHI-aims` (supporting notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import exists, join\n",
    "import chemiscope\n",
    "\n",
    "import numpy as np\n",
    "import metatensor as mts\n",
    " \n",
    "from rholearn.utils import cube, system\n",
    "from rholearn.utils.io import unpickle_dict\n",
    "from rholearn.options import get_options\n",
    "\n",
    "dft_options = get_options(\"dft\", \"rholearn\")\n",
    "dft_options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the nuclear geometries with chemiscope\n",
    "frames = system.read_frames_from_xyz(dft_options[\"XYZ\"])\n",
    "frame_idxs = range(len(frames))\n",
    "chemiscope.show(system.chemfiles_frame_to_ase_frame(frames), mode=\"structure\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2: Converge SCF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check all SCF calculations have converged\n",
    "scf_dir = lambda A: f\"data/raw/{A}\"\n",
    "\n",
    "not_conv = []\n",
    "for A in frame_idxs:\n",
    "    path = join(scf_dir(A), \"aims.out\")\n",
    "    if not exists(path):\n",
    "        not_conv.append(A)\n",
    "    else:\n",
    "        with open(path, \"r\") as f:\n",
    "            if \"Have a nice day.\" not in f.read():\n",
    "                not_conv.append(A)\n",
    "\n",
    "assert len(not_conv) == 0, f\"SCF not converged for {not_conv}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm again all SCF calculations have converged via the parsed aims.out files\n",
    "for A in frame_idxs:\n",
    "    calc_info = unpickle_dict(join(scf_dir(A), \"calc_info.pickle\"))\n",
    "    assert calc_info[\"scf\"][\"converged\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WARNING: execute with care! \n",
    "# Display the electron density volumetric data. This relies on py3Dmol, which is often\n",
    "# unreliable in jupyter notebooks. Better to use another external software, such as\n",
    "# VESTA.\n",
    "\n",
    "# Display the electron density of structure 0\n",
    "A = 0\n",
    "rhocube = cube.RhoCube(join(scf_dir(A), \"cube_001_total_density.cube\"))\n",
    "rhocube.show_volumetric()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3: Perform RI decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check all RI calculations have finished\n",
    "ri_dir = lambda A: f\"data/raw/{A}/edensity\"\n",
    "\n",
    "not_finished = []\n",
    "for A in frame_idxs:\n",
    "    path = join(ri_dir(A), \"aims.out\")\n",
    "    if not exists(path):\n",
    "        not_conv.append(A)\n",
    "    else:\n",
    "        with open(path, \"r\") as f:\n",
    "            if \"Have a nice day.\" not in f.read():\n",
    "                not_conv.append(A)\n",
    "\n",
    "assert len(not_finished) == 0, f\"RI not finished for {not_finished}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inpsect the basis set definition for frame 0\n",
    "processed_dir = lambda A: f\"data/processed/{A}/edensity\"  # relative dir\n",
    "\n",
    "A = 0\n",
    "unpickle_dict(join(processed_dir(A), \"basis_set.pickle\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the metadata structure of the coefficient vector and overlap matrix\n",
    "coeffs = mts.load(join(processed_dir(A), \"ri_coeffs.npz\"))\n",
    "ovlp = mts.load(join(processed_dir(A), \"ri_ovlp.npz\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The coefficient (and projection) vector is a 1D array, stored in a block sparse\n",
    "# format. As it represents an equivariant target property (i.e. the density decomposed\n",
    "# onto a spherical basis), knowing the spherical symmetry of each block - in terms of\n",
    "# `o3_lambda` and `o3_sigma` - is crucial for unserstanding the bahviour under rotation\n",
    "# and what equivariance-preserving operations can be applied.\n",
    "coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first axis of each block is the atomic samples. The intermediate axis is the\n",
    "# spherical harmonics components, and the properties (last axis) is the radial basis\n",
    "# function index.\n",
    "coeffs.block(o3_lambda=1, o3_sigma=1, center_type=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The overlap matrix is stored with pairs of center types (i.e. chemical species) as\n",
    "# sparse keys. These have consistent basis set definitions, so overlap matrices between\n",
    "# atoms can be stacked.\n",
    "ovlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each center type pair, the overlaps between basis functions of pairs of atoms of\n",
    "# types center_1_type and center_2_type are stacked along the samples (first) axis.\n",
    "ovlp.block(center_1_type=6, center_2_type=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the normalised MAE, averaged over all structures\n",
    "nmaes = []\n",
    "for A in frame_idxs:\n",
    "    df_error = unpickle_dict(\n",
    "        join(processed_dir(A), \"df_error.pickle\")\n",
    "    )\n",
    "    nmae = 100 * df_error['abs_error'] / df_error['norm']\n",
    "    nmaes.append(nmae)\n",
    "\n",
    "print(\"NMAE (%)\")\n",
    "print(\"   Min  : \", np.min(nmaes))\n",
    "print(\"   Mean : \", np.mean(nmaes))\n",
    "print(\"   Max  : \", np.max(nmaes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: check that the RI rebuilt density output in the RI procesure is equivalent\n",
    "# to the density rebuilt from the corresponding coefficients.\n",
    "from rholearn.aims_interface import fields\n",
    "\n",
    "rebuild_dir = lambda A: f\"data/raw/{A}/edensity/rebuild\"  # relative dir\n",
    "\n",
    "# Check for the first structure\n",
    "A = 0\n",
    "abs_error, norm = fields.field_absolute_error(\n",
    "    input=np.loadtxt(join(rebuild_dir(A), \"rho_rebuilt_ri.out\")),\n",
    "    target=np.loadtxt(join(ri_dir(A), \"rho_rebuilt_ri.out\")),\n",
    "    grid=np.loadtxt(join(ri_dir(A), \"partition_tab.out\"))\n",
    ")\n",
    "\n",
    "assert 100 * abs_error / norm < 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rho",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
